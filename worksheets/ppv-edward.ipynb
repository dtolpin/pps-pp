{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import numpy.random\n",
    "\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "from edward.models import Bernoulli, Exponential, Normal, Gamma, Empirical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_COUNT = 10\n",
    "PAGES_PER_SESSION_PRIOR = 5\n",
    "NUMBER_OF_SESSIONS = 100\n",
    "\n",
    "DECAY = 2.\n",
    "\n",
    "# Simulate some trend\n",
    "TREND = PAGES_PER_SESSION_PRIOR * numpy.exp(- numpy.arange(NUMBER_OF_SESSIONS) * DECAY \n",
    "                                            / NUMBER_OF_SESSIONS) \n",
    "         \n",
    "\n",
    "# Sample data around the trend\n",
    "DATA = numpy.minimum(PAGE_COUNT, \n",
    "                     numpy.maximum(1, numpy.round(numpy.random.exponential(TREND))))\n",
    "\n",
    "print(\"Trend from {:.2f} to {:.2f}\".format(TREND[0], TREND[-1]))\n",
    "print(\"Data:\", DATA)\n",
    "\n",
    "# Convert to tensor\n",
    "DATA = tf.convert_to_tensor(DATA, numpy.int32)\n",
    "with tf.Session() as s:\n",
    "    print(s.run(DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model of clicking through a campaign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beliefs(beliefs, i, j, bandwidth):\n",
    "    \n",
    "    # updates the beliefs with new evidence\n",
    "    update = tf.scatter_nd(tf.stack([tf.stack([i , j])]),\n",
    "                           tf.constant([1.]),\n",
    "                           beliefs.shape)\n",
    "    beliefs = beliefs + update\n",
    "    \n",
    "    # compute new evidence in the updated row\n",
    "    evidence = tf.reduce_sum(beliefs[i, :])\n",
    "    \n",
    "    # if the evidence is greater than the bandwidth,\n",
    "    # scale down\n",
    "    scale = bandwidth / evidence\n",
    "    beliefs = tf.cond(scale < 1.,\n",
    "                      lambda: beliefs * \n",
    "                              tf.exp(tf.scatter_nd(tf.stack([tf.stack([i, tf.constant(0)]),\n",
    "                                                             tf.stack([i, tf.constant(1)])]),\n",
    "                                                   tf.log(tf.stack([scale, scale])),\n",
    "                                                   beliefs.shape)),\n",
    "                      lambda: beliefs)\n",
    "    return beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "foo = update_beliefs(tf.constant([[3., 4.], [3., 3.]]), tf.constant(1), tf.constant(0), tf.constant(1.))\n",
    "with tf.Session() as s:\n",
    "    print(s.run(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(bandwidth, page_count, number_of_sessions, data):\n",
    "    churn_probability = 1 / PAGES_PER_SESSION_PRIOR\n",
    "    beliefs = tf.stack([2 * churn_probability * tf.ones(page_count),\n",
    "                        2 * (1 - churn_probability) * tf.ones(page_count)],\n",
    "                       axis=1)\n",
    " \n",
    "    def over_sessions(state, isession):\n",
    "       \n",
    "        def over_pages(beliefs, ipage, last_page):\n",
    "            last_page = tf.logical_or(tf.equal(ipage, data[isession] - 1),\n",
    "                                      tf.equal(ipage, page_count - 1))\n",
    "            beliefs = update_beliefs(beliefs, ipage, \n",
    "                                     tf.cond(last_page, lambda: 0, lambda: 1),\n",
    "                                     bandwidth) \n",
    "            return (beliefs, ipage + 1, last_page)\n",
    "\n",
    "        def continues(lefts, ipage, last_page):\n",
    "            return tf.logical_not(last_page)\n",
    "\n",
    " \n",
    "        beliefs, _ = state\n",
    "        beliefs, _, _ = tf.while_loop(continues, over_pages, (beliefs, 0, tf.constant(False)))\n",
    "        \n",
    "        return beliefs, beliefs\n",
    "    \n",
    "    _, beliefs = tf.scan(over_sessions, tf.range(number_of_sessions), (beliefs, beliefs))\n",
    "    \n",
    "    # Prepend to each session's lefts 0 and append 1 to get the correct number: never\n",
    "    # left after 0 pages, always left by reaching the end\n",
    "    scattered_lefts = Bernoulli(probs=beliefs[:, :, 0] / (beliefs[:, :, 0] + beliefs[:, :, 1]))\n",
    "    scattered_lefts = tf.concat([tf.zeros((scattered_lefts.shape[0], 1), dtype=tf.int32),\n",
    "                                 scattered_lefts[:, :-1],\n",
    "                                 tf.ones((scattered_lefts.shape[0], 1), dtype=tf.int32)],\n",
    "                                axis=1)\n",
    "    lefts = tf.argmax(scattered_lefts, axis=1)\n",
    "    \n",
    "    return Normal(tf.cast(lefts, dtype=tf.float32), scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "foo = model(20., PAGE_COUNT, NUMBER_OF_SESSIONS, DATA)\n",
    "with tf.Session() as s:\n",
    "    a = 0.\n",
    "    b = 0.\n",
    "    K = 100\n",
    "    for i in range(100):\n",
    "        res = s.run(foo)\n",
    "        a += res[:len(res)//4].mean()\n",
    "        b += res[-len(res)//4:].mean()\n",
    "    a /= K\n",
    "    b /= K\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = Exponential(0.05)\n",
    "pps = model(bandwidth, PAGE_COUNT, NUMBER_OF_SESSIONS, DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just see we still can run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as s:\n",
    "    resum = numpy.zeros(DATA.shape[0])\n",
    "    K = 10\n",
    "    for i in range(K):\n",
    "        res = s.run(pps)\n",
    "        resum += res\n",
    "    resum /= K\n",
    "    print(resum)\n",
    "    d = 10\n",
    "    plt.plot([resum[i:i+d].mean() for i in range(len(resum))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MH Monte Carlo\n",
    "\n",
    "Slow but should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "with tf.variable_scope(\"importance\", reuse=tf.AUTO_REUSE):\n",
    "    sampled_bandwidth = Empirical(params=tf.get_variable(\n",
    "        \"sampled_bandwidth\", \n",
    "        [N], \n",
    "        initializer=tf.constant_initializer(10.)))\n",
    "    proposed_bandwidth = Normal(loc=sampled_bandwidth, scale=1.)\n",
    "\n",
    "    mh_inference = ed.MetropolisHastings({bandwidth: sampled_bandwidth}, \n",
    "                                         {bandwidth: proposed_bandwidth},\n",
    "                                         data={pps: tf.cast(DATA, tf.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mh_inference.run()\n",
    "\n",
    "sess = ed.get_session()\n",
    "mean, stddev = sess.run([sampled_bandwidth.mean(), sampled_bandwidth.stddev()])\n",
    "print(\"posterior: mean={:.4f}, stddev={:.4f}\".format(mean, stddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(sess.run(sampled_bandwidth.sample(1000)), density=True)\n",
    "_ = plt.xlabel(\"bandwidth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Variational Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"variational\", reuse=tf.AUTO_REUSE):\n",
    "    shape = tf.get_variable(\"shape\", (), initializer=tf.constant_initializer(1.))\n",
    "    scale = tf.get_variable(\"scale\", (), initializer=tf.constant_initializer(20.))\n",
    "    qbandwidth = Gamma(tf.nn.softplus(shape), 1. / tf.nn.softplus(scale))\n",
    "\n",
    "variational_inference = ed.KLqp({bandwidth: qbandwidth}, \n",
    "                                data={pps: tf.cast(DATA, tf.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_inference.run(n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = qbandwidth.concentration.eval()\n",
    "beta = qbandwidth.rate.eval()\n",
    "mean = alpha / beta\n",
    "stddev = numpy.sqrt(mean / beta)\n",
    "print(\"posterior: mean={:.4f} stddev={:.4f}\".format(mean, stddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(qbandwidth.sample(1000).eval(), density=True)\n",
    "_ = plt.xlabel(\"bandwidth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
