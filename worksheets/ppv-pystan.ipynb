{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"/Users/dtolpin/venv/stan/lib/python3.7/site-packages/\")\n",
    "import pystan\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_PAGES = 10\n",
    "PAGES_PER_SESSION_PRIOR = 5\n",
    "NUMBER_OF_SESSIONS = 100\n",
    "\n",
    "DECAY = 2\n",
    "\n",
    "# Simulate some trend\n",
    "TREND = PAGES_PER_SESSION_PRIOR * numpy.exp(- numpy.arange(NUMBER_OF_SESSIONS) * DECAY \n",
    "                                            / NUMBER_OF_SESSIONS) \n",
    "         \n",
    "\n",
    "# Sample data around the trend\n",
    "DATA = numpy.minimum(NUMBER_OF_PAGES,\n",
    "                          numpy.maximum(1, \n",
    "                                        numpy.round(numpy.random.exponential(TREND))))\n",
    "\n",
    "print(\"Trend from {:.2f} to {:.2f}\".format(TREND[0], TREND[-1]))\n",
    "print(\"Data:\", DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_code = \"\"\"\n",
    "data {\n",
    "    int npages;                // number of pages\n",
    "    int nsessions;            // number of sessions    \n",
    "    vector[nsessions] pps;    // page counts (per session)\n",
    "    real prior_bandwidth;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0> bandwidth;\n",
    "}\n",
    "\n",
    "model {\n",
    "    // initialize beliefs\n",
    "    real beliefs[npages, 2];\n",
    "    real churn_probability = 2. / npages;\n",
    "    int churned;\n",
    "    \n",
    "    for(i in 1:npages) {\n",
    "        beliefs[i][1] = 2. * churn_probability;\n",
    "        beliefs[i][2] = 2. * (1 - churn_probability);\n",
    "    }\n",
    "    \n",
    "    // put a prior on the bandwidth\n",
    "    target += -bandwidth / prior_bandwidth;\n",
    "    \n",
    "\n",
    "    for (i in 1:nsessions) {\n",
    "        for(j in 1:npages) {\n",
    "            if(j < pps[i]) {\n",
    "                churned = 0;\n",
    "            } else {\n",
    "                churned = 1;\n",
    "            }\n",
    "\n",
    "            // observe the pps and update the belief\n",
    "            {\n",
    "                real evidence = beliefs[j, 1] + beliefs[j, 2];\n",
    "                if(churned) {\n",
    "                    target += log(beliefs[j, 1] / evidence);\n",
    "                    beliefs[j, 1] += 1;\n",
    "                } else {\n",
    "                    target += log(beliefs[j, 2] / evidence);\n",
    "                    beliefs[j, 2] += 1;\n",
    "                }\n",
    "\n",
    "                // discount the beliefs based on the bandwidth\n",
    "                if(evidence >= bandwidth) {\n",
    "                    real discount = bandwidth / evidence;\n",
    "                    beliefs[j, 1] *= discount;\n",
    "                    beliefs[j, 2] *= discount;\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            if(churned)\n",
    "                break;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True: # enable to rebuild the model\n",
    "    pps_data = {'npages': NUMBER_OF_PAGES,\n",
    "                'nsessions': NUMBER_OF_SESSIONS,\n",
    "                'pps': DATA.tolist(),\n",
    "                'prior_bandwidth': 100}\n",
    "\n",
    "    sm = pystan.StanModel(model_code=pps_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit = sm.sampling(data=pps_data, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing the predicted bandwidth directly through pyplot because `fit.plot()` is buggy and arviz is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = fit.extract()\n",
    "mean, std = la['bandwidth'].mean(), la['bandwidth'].std()\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title('predicted bandwidth')\n",
    "plt.xlabel('bandwidth')\n",
    "plt.ylabel('density')\n",
    "hist = plt.hist(la['bandwidth'], density=True, color='lightblue')\n",
    "plt.vlines(ymin=0, ymax=hist[0].max() * 1.05, x=[mean], lw=2, label='mean', color='darkgray')\n",
    "plt.vlines(ymin=0, ymax=hist[0].max()/2, x=[mean - std, mean+ std],\n",
    "           lw=1.25, linestyles='dashed', label='mean ± std',\n",
    "           color='darkgray')\n",
    "plt.vlines(ymin=0, ymax=hist[0].max()/4, x=[mean - 2 * std, mean + 2 * std], \n",
    "           lw=0.75,linestyles='dotted', label='mean ± 2 * std',\n",
    "           color='darkgray')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
