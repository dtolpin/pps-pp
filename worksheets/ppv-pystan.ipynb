{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"/Users/dtolpin/venv/stan/lib/python3.7/site-packages/\")\n",
    "import pystan\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend from 5.00 to 0.68\n",
      "Data: [10.  6.  2.  5.  2.  3.  1.  5.  6.  5.  1.  3.  1.  1.  3.  2.  6.  3.\n",
      "  5.  6.  2.  1.  3.  7.  1.  4.  1.  5.  1.  6.  4.  2.  7.  4.  3.  5.\n",
      "  9.  6.  1.  4.  1.  3.  1. 10.  9.  1. 10.  3.  4.  1. 10. 10.  9.  1.\n",
      "  5.  1.  6.  2.  2.  3.  1.  5.  3.  4.  3.  1.  1.  3.  4.  1.  3.  2.\n",
      "  3.  4.  4.  7.  3.  5.  2. 10.  1.  2.  2.  3.  2.  3.  1.  2.  1.  1.\n",
      "  4. 10.  8.  1.  1.  1.  2.  1.  5. 10.  1.  2.  1.  8.  1.  1.  6.  4.\n",
      "  1.  6.  3.  3.  7.  2.  1.  1.  1.  3.  3.  3.  1.  1.  3.  9.  5. 10.\n",
      "  9.  1.  5.  5.  1.  2.  5. 10.  2.  1.  8.  7.  6.  1.  7.  1.  1.  8.\n",
      "  3.  1.  6.  5.  5.  1.  7.  3.  1.  2.  2.  1.  3.  1.  1.  1.  1.  1.\n",
      "  1.  2.  1.  6.  1.  1.  2.  4.  2.  2.  1.  1.  1.  5. 10.  6.  4.  4.\n",
      "  1.  1.  1. 10.  1.  2.  1. 10.  1.  1.  4.  1.  2.  1. 10.  6.  1.  5.\n",
      "  1.  2. 10.  2. 10.  3.  5.  1.  1.  2.  6.  2.  1.  1.  1. 10.  8.  1.\n",
      "  1.  1.  3.  9.  2.  9.  2.  2.  2.  4.  1.  3.  1.  1.  3.  6.  8.  3.\n",
      "  2.  5.  1.  1.  1.  3.  6.  1.  1. 10.  1.  3.  4.  2.  2.  1.  1.  1.\n",
      "  1.  4.  1.  1. 10.  2.  7.  1.  1.  2.  3. 10. 10.  1.  1.  5.  3.  3.\n",
      "  3.  1. 10.  1.  1.  3.  9.  5.  5.  1.  3.  2.  4.  1. 10.  1.  2.  2.\n",
      "  4.  1.  1.  5.  3.  7. 10.  2.  5.  1.  1.  6.  1.  1.  1.  3.  4. 10.\n",
      "  3.  6.  4.  2.  3.  5.  9.  2.  3.  3.  3.  2.  1.  1.  3.  1.  1.  1.\n",
      "  1.  5.  1.  1.  4.  2.  1.  4.  1.  4.  1.  6. 10.  1.  1.  1.  1.  5.\n",
      "  6.  9.  7.  1.  3.  7.  2.  3.  1.  2.  1.  8.  2.  1.  2. 10. 10.  2.\n",
      "  1.  5.  4.  1.  1.  1.  5.  2.  3.  3.  1.  2.  2.  6.  1.  2.  1.  1.\n",
      "  2.  1.  1.  2.  5.  2.  1.  1.  7.  1.  3.  2.  1.  2.  1.  1.  1.  1.\n",
      "  1.  1.  1.  4.  1.  1.  3.  6.  1.  2.  4.  5.  2.  1.  4.  1.  2.  1.\n",
      "  8.  3.  4.  1.  1.  1.  1.  3.  1.  1.  1.  4.  2.  2.  1.  2.  1.  2.\n",
      "  2.  3.  3.  1.  1.  1.  2.  2.  2.  1.  1.  2.  1.  1.  1.  1. 10.  5.\n",
      "  1.  2.  1.  1.  2.  1.  6.  2.  2.  2.  1.  1.  2.  5.  1.  1.  1.  4.\n",
      "  1.  2.  1.  1.  2.  1.  1.  1.  1.  1.  6.  1.  3.  4.  1.  2.  5.  1.\n",
      "  5.  1.  2.  1. 10.  2.  2.  1.  7.  2.  2.  1.  5.  1.  1.  1.  1.  1.\n",
      "  1.  3.  1.  2.  1.  2.  1.  1.  2.  1.  3.  2.  5.  1.  1.  2.  1.  1.\n",
      "  4.  1.  2.  2.  4.  1.  2.  2.  1.  1.  1.  1.  2.  6.  2.  4.  1.  6.\n",
      "  1.  1.  1.  3.  3.  2.  2.  3.  1.  2.  2.  1.  3.  1.  2.  1.  2.  1.\n",
      "  6.  6.  1.  2.  3.  1.  2.  1.  3.  1.  1.  1.  1.  3.  1.  3.  3.  1.\n",
      "  2.  4.  1.  2.  5.  1.  4.  1.  3.  1.  2.  3.  1.  4.  2.  5.  1.  1.\n",
      "  1.  2.  1.  2.  1.  5.  1.  1.  2.  1.  1.  3.  1.  1.  3.  1.  3.  1.\n",
      "  1.  1.  1.  1.  2.  2.  1.  1.  1.  4.  2.  3.  7.  1.  2.  1.  2.  6.\n",
      "  6.  1.  1.  3.  1.  2.  1.  1.  3.  1.  1.  1.  1.  1.  1.  2.  2.  1.\n",
      "  1.  1.  2.  1.  4.  1.  2.  3.  1.  3.  2.  1.  1.  1.  1.  1.  1.  2.\n",
      "  1.  2.  1.  1.  1.  1.  1.  2.  6.  1.  2.  1.  1.  1.  2.  1.  1.  3.\n",
      "  2.  1.  1.  1.  1.  1.  3.  3.  2.  1.  1.  1.  1.  1.  1.  1.  2.  2.\n",
      "  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  3.  1.\n",
      "  2.  1.  1.  1.  1.  5.  1.  1.  1.  2.  3.  1.  1.  2.  1.  1.  1.  1.\n",
      "  1.  2.  1.  2.  3.  1.  1.  1.  1.  3.  3.  3.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  2.  3.  1.  1.  1.  1.  1.  1.  2.  5.  1.  2.  1.  1.  1.\n",
      "  1.  4.  1.  1.  1.  1.  1.  1.  5.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  3.  1.  1.  1.  1.  3.  2.\n",
      "  1.  2.  1.  2.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  2.  4.  1.  1.\n",
      "  1.  2.  1.  1.  1.  2.  1.  2.  2.  1.  1.  1.  2.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  1.  1.  2.  2.  1.  1.  1.  1.  2.\n",
      "  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  2.  1.  1.  1.  1.  1.  2.  2.\n",
      "  1.  2.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.\n",
      "  2.  1.  1.  2.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  3.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  2.  1.  1.  1.  1.  2.  2.  1.  1.  3.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  1.  1.  1.  1.  1.\n",
      "  1.  1.  2.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_PAGES = 10\n",
    "PAGES_PER_SESSION_PRIOR = 5\n",
    "NUMBER_OF_SESSIONS = 1000\n",
    "\n",
    "DECAY = 2\n",
    "\n",
    "# Simulate some trend\n",
    "TREND = PAGES_PER_SESSION_PRIOR * numpy.exp(- numpy.arange(NUMBER_OF_SESSIONS) * DECAY \n",
    "                                            / NUMBER_OF_SESSIONS) \n",
    "         \n",
    "\n",
    "# Sample data around the trend\n",
    "DATA = numpy.minimum(NUMBER_OF_PAGES,\n",
    "                          numpy.maximum(1, \n",
    "                                        numpy.round(numpy.random.exponential(TREND))))\n",
    "\n",
    "print(\"Trend from {:.2f} to {:.2f}\".format(TREND[0], TREND[-1]))\n",
    "print(\"Data:\", DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps_code = \"\"\"\n",
    "data {\n",
    "    int npages;                // number of pages\n",
    "    int nsessions;            // number of sessions    \n",
    "    vector[nsessions] pps;    // page counts (per session)\n",
    "    real prior_bandwidth;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real<lower=0> bandwidth;\n",
    "}\n",
    "\n",
    "model {\n",
    "    // initialize beliefs\n",
    "    real beliefs[npages, 2];\n",
    "    real churn_probability = 2. / npages;\n",
    "    int churned;\n",
    "    \n",
    "    for(i in 1:npages) {\n",
    "        beliefs[i][1] = 2. * churn_probability;\n",
    "        beliefs[i][2] = 2. * (1 - churn_probability);\n",
    "    }\n",
    "    \n",
    "    // put a prior on the bandwidth\n",
    "    target += -bandwidth / prior_bandwidth;\n",
    "    \n",
    "\n",
    "    for (i in 1:nsessions) {\n",
    "        for(j in 1:npages) {\n",
    "            if(j < pps[i]) {\n",
    "                churned = 0;\n",
    "            } else {\n",
    "                churned = 1;\n",
    "            }\n",
    "\n",
    "            // observe the pps and update the belief\n",
    "            {\n",
    "                real evidence = beliefs[j, 1] + beliefs[j, 2];\n",
    "                if(churned) {\n",
    "                    target += log(beliefs[j, 1] / evidence);\n",
    "                    beliefs[j, 1] += 1;\n",
    "                } else {\n",
    "                    target += log(beliefs[j, 2] / evidence);\n",
    "                    beliefs[j, 2] += 1;\n",
    "                }\n",
    "\n",
    "                // discount the beliefs based on the bandwidth\n",
    "                if(evidence >= bandwidth) {\n",
    "                    real discount = bandwidth / evidence;\n",
    "                    beliefs[j, 1] *= discount;\n",
    "                    beliefs[j, 2] *= discount;\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            if(churned)\n",
    "                break;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_2417f640540ab972ddcf0427ba229580 NOW.\n"
     ]
    }
   ],
   "source": [
    "pps_data = {'npages': NUMBER_OF_PAGES,\n",
    "            'nsessions': NUMBER_OF_SESSIONS,\n",
    "            'pps': DATA.tolist(),\n",
    "            'prior_bandwidth': 100}\n",
    "\n",
    "if True: # enable to rebuild the model\n",
    "    sm = pystan.StanModel(model_code=pps_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the optimum bandwidth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "optim = sm.optimizing(data=pps_data, as_vector=False,\n",
    "                      init={'bandwidth': pps_data['prior_bandwidth']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best bandwidth: %.6g\\nlog-posterion: %.6g\" % \n",
    "      (optim['par']['bandwidth'], optim['value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit = sm.sampling(data=pps_data, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing the predicted bandwidth directly through pyplot because `fit.plot()` is buggy and arviz is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = fit.extract()\n",
    "mean, std = la['bandwidth'].mean(), la['bandwidth'].std()\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title('predicted bandwidth')\n",
    "plt.xlabel('bandwidth')\n",
    "plt.ylabel('density')\n",
    "hist = plt.hist(la['bandwidth'], density=True, color='lightblue')\n",
    "plt.vlines(ymin=0, ymax=hist[0].max() * 1.05, x=[mean], lw=2, label='mean', color='darkgray')\n",
    "plt.vlines(ymin=0, ymax=hist[0].max()/2, x=[mean - std, mean+ std],\n",
    "           lw=1.25, linestyles='dashed', label='mean ± std',\n",
    "           color='darkgray')\n",
    "plt.vlines(ymin=0, ymax=hist[0].max()/4, x=[mean - 2 * std, mean + 2 * std], \n",
    "           lw=0.75,linestyles='dotted', label='mean ± 2 * std',\n",
    "           color='darkgray')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
